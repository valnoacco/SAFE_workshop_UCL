{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5952e15b",
   "metadata": {},
   "source": [
    "# GSA workflow tutorial\n",
    "Fanny Sarrazin (fanny.sarrazin@ufz.de), Andres Peñuela (apenuela@uco.es); 2022-11-02\n",
    "\n",
    "The goal of this session is to give a flavour of Sensitivity Analysis by application  of several methods to a simple rainfall-runoff model.\n",
    "\n",
    "The uncertain inputs subject to SA are the model parameters. The aim is to assess the impact of the uncertainty in these parameters on the model's ability to reproduce streamflow observations, as measured by different\n",
    "performance metrics:\n",
    "- the Root Mean Squared Error (RMSE)\n",
    "- the volumetric bias (BIAS)\n",
    "\n",
    "The analysis will be conducted using the [SAFE(R/Python/Matlab) Toolbox](https://safetoolbox.github.io) (Pianosi et al., 2015).\n",
    "\n",
    "Programme:\n",
    "\n",
    " 1. **Model setup and One-At-a-Time Sensitivity Analysis (OAT)**:\n",
    "    Load the data and get confident with the rainfall-runoff model (Hymod)\n",
    "\n",
    " 2. **Visual and qualitative Global Sensitivity Analysis (GSA)**:\n",
    "    Perform Monte Carlo simulations (forward propagation of uncertainty), i.e.\n",
    "    sample the model parameters within their ranges and run the model to\n",
    "    obtain an ensemble of runoff predictions. Use a visual and qualitative\n",
    "    GSA method for a preliminary assessment of sensitivity (scatterplots).\n",
    "\n",
    " 3. **Regional Sensitivity Analysis (RSA)**:\n",
    "    Use RSA to formally assess the effect of parameter variations on the model \n",
    "    outputs.\n",
    "    (Young et al., 1978; Spear and Hornberger, 1980; Saltelli et al., 2008)\n",
    "    \n",
    " 4. **Regional Sensitivity Analysis based on grouping**: \n",
    "    Use RSA based on grouping to assess the output sensitivity without \n",
    "    specifying a single threshold on output values.\n",
    "    (Wagener et al., 2001)\n",
    "\n",
    "Throughout the session, we will also examine the impact of several key choices on SA results: <br> \n",
    "- the threshold value for RSA \n",
    "- the output (scalar) metric\n",
    "- the sample size for the Monte Carlo simulations\n",
    "- the parameter ranges\n",
    "- the SA method\n",
    "\n",
    "Further investigation of these choices can be found in Noacco et al.\n",
    "(2019), and a general discussion on the topic is also provided in\n",
    "Pianosi et al. (2016) and in Wagener and Pianosi (2019). The choice of\n",
    "sample size is more specifically discussed in Sarrazin et al. (2016).\n",
    "\n",
    "**Hymod model**:\n",
    "\n",
    "We will use the Hymod (Boyle 2001; Wagener et al. 2001) model, which\n",
    "produces a time series of streamflow predictions as output. The model is\n",
    "composed of a soil moisture accounting routine, and a flow routing routine,\n",
    "which in its turn is composed of a fast and a slow routing pathway.\n",
    "The model is applied to the Leaf catchment in the USA (Sorooshian et al.,\n",
    "1983).\n",
    "\n",
    "![hymod_model](images/hymod_model.png)\n",
    "\n",
    "Hymod includes 5 parameters:\n",
    "- **Sm**: the maximum soil moisture (mm) (soil moisture)\n",
    "- **beta**: the exponent in the soil moisture (-) (soil moisture)\n",
    "- **alfa**: the partition coefficient (-) (routing)\n",
    "- **Rs**: the slow reservoir coefficient (-) (routing)\n",
    "- **Rf**: the fast reservoir coefficient (-) (routing)\n",
    "\n",
    "The model is applied to the Leaf catchment in the USA (Sorooshian et al., 1983).\n",
    "\n",
    "![leaf_catchment](images/leaf_catchment.png)\n",
    "\n",
    "The model forcing input data are:\n",
    "- 1-year daily observations of rainfall (R) [column 1 in LeafCatch.txt]\n",
    "- 1-year daily observations potential evaporation (PE) [column 2 in the file\n",
    "LeafCatch.txt]\n",
    "\n",
    "We will also used output measurements:\n",
    "- 1-year daily observations of streamflow (Q) [column 3 in LeafCatch.txt]\n",
    "\n",
    "For this application, we can use the following ranges of feasible variations of the parameters:\n",
    "- SM ∈ [0,400] (mm)\n",
    "- beta ∈ [0,2] (-)\n",
    "- alfa ∈ [0,1] (-)\n",
    "- RS ∈ [0,0.1] (-)\n",
    "- RF ∈ [0.1,1] (-)\n",
    "\n",
    "\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8c12ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd0f6ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'BIAS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34605/3133555810.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Import the additional function BIAS in the BIAS.py module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBIAS\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBIAS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'BIAS'"
     ]
    }
   ],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatRangeSlider, IntRangeSlider\n",
    "import scipy.stats as st\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to hide warning messages\n",
    "\n",
    "sys.path.append(\"../../SAFE-python\")\n",
    "\n",
    "# Module to perform Regional Sensitivity Analysis:\n",
    "import SAFEpython.RSA_thres as RSA_tr\n",
    "# Module to perform Regional Sensitivity Analysis based on grouping:\n",
    "import SAFEpython.RSA_groups as RSA_gp\n",
    "# Module to visualize the results:\n",
    "import SAFEpython.plot_functions as pf\n",
    "# Module to execute the model\n",
    "from SAFEpython.model_execution import model_execution\n",
    "# Functions to perform the input sampling\n",
    "from SAFEpython.sampling import AAT_sampling, AAT_sampling_extend\n",
    "# Function to calculate RMSE:\n",
    "from SAFEpython.util import aggregate_boot, RMSE\n",
    "# Module that simulates the HyMod model:\n",
    "from SAFEpython import HyMod\n",
    "\n",
    "# Import the additional function BIAS in the BIAS.py module\n",
    "from BIAS import BIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07c616",
   "metadata": {},
   "source": [
    "## 1. Model setup and One-At-a-Time Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82078b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify the directory where the data are stored \n",
    "mydir = '../../SAFE-python/data'\n",
    "\n",
    "# Load data and plot the data (one year of daily observations of rainfall, \n",
    "# potential evaporation and flow):\n",
    "\n",
    "# Load data:\n",
    "data = np.genfromtxt(mydir +'//LeafCatch.txt', comments='%')\n",
    "rain = data[0:365, 0] # select the first year of data\n",
    "evap = data[0:365, 1]\n",
    "flow = data[0:365, 2]\n",
    "warmup = 30 # Model warmup period (days)\n",
    "\n",
    "# Plot data:\n",
    "plt.figure(figsize=[15,7])\n",
    "plt.subplot(311); plt.plot(rain); plt.ylabel('rainfall (mm/day)')\n",
    "plt.subplot(312); plt.plot(evap); plt.ylabel('evaporation (mm/day)')\n",
    "plt.subplot(313); plt.plot(flow, color=[0.7, 0.7, 0.7]); plt.ylabel('flow (mm/day)')\n",
    "plt.xlabel('time (days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f01c23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the parameters to some tentative values, run the model and plot the \n",
    "# resulting streamflow time series:\n",
    "\n",
    "def hymod_sim_mod(param, rain, ept):\n",
    "    \n",
    "    \"\"\"This function simulates the Hymod rainfall-runoff model\n",
    "    (Boyle, 2001; Wagener et al., 2001). \n",
    "    It is modified from HyMod.hymod_sim in the SAFE package\"\"\"\n",
    "\n",
    "    ###########################################################################\n",
    "    # Recover model parameters\n",
    "    ###########################################################################\n",
    "    Sm = max(np.spacing(1), param[0]) # Maximum Soil Moisture (cannot\n",
    "                                              # be zero! ) See lines 35 and 37)\n",
    "    beta = param[1] # Exponential parameter in soil routine [-]\n",
    "    alfa = param[2] # Partitioning factor [-]\n",
    "    Rs = param[3] # Slow reservoir outflow coefficient (ratio) [1/Dt]\n",
    "    Rf = param[4] # Fast reservoir outflow coefficient (ratio) [1/Dt]\n",
    "    rain_e = param[5] # Rainfall error [-]\n",
    "\n",
    "    T = len(rain)\n",
    "\n",
    "    ###########################################################################\n",
    "    # Initialise variables\n",
    "    ###########################################################################\n",
    "    Pe = np.zeros((T, )) # Recharge from the soil [mm/Dt]\n",
    "    Ea = np.zeros((T, )) # Actual Evapotranspiration [mm/Dt]\n",
    "    sm = np.zeros((T+1, )) # Soil Moisture [mm]\n",
    "    sL = np.zeros((T+1, )) # Slow reservoir moisture [mm]\n",
    "    sF1 = np.zeros((T+1, )) # Fast reservoir 1 moisture [mm]\n",
    "    sF2 = np.zeros((T+1, )) # Fast reservoir 2 moisture [mm]\n",
    "    sF3 = np.zeros((T+1, )) # Fast reservoir 3 moisture [mm]\n",
    "    QsL = np.zeros((T, )) # Slow flow [mm/Dt]\n",
    "    QsF = np.zeros((T, )) # Fast flow [mm/Dt]\n",
    "\n",
    "    for t in range(T):\n",
    "    ###########################################################################\n",
    "    # Soil moisture dynamics\n",
    "    ###########################################################################\n",
    "        F = 1 - (1-sm[t]/Sm)**beta\n",
    "        Pe[t] = F * rain[t] * rain_e # Compute the value of the outflow\n",
    "        # (we assumed that this process is faster than evaporation)\n",
    "        sm_temp = max(min(sm[t] + rain[t] * rain_e - Pe[t], Sm), 0)\n",
    "        # Compute the water balance with the value of the outflow\n",
    "        Pe[t] = Pe[t] + max(sm[t] + rain[t] * rain_e - Pe[t] - Sm, 0) + \\\n",
    "                min(sm[t] + rain[t] - Pe[t], 0)\n",
    "        # Adjust Pe by an amount equal to the possible negative sm amount or\n",
    "        # to the possible sm amount above Sm.\n",
    "\n",
    "        W = min(np.abs(sm[t]/Sm), 1) # Correction factor for evaporation\n",
    "        Ea[t] = W * ept[t] # Compute the evaporation\n",
    "        sm[t+1] = max(min(sm_temp - Ea[t], Sm), 0) # Compute the water balance\n",
    "        Ea[t] = Ea[t] + max(sm_temp - Ea[t] - Sm, 0) + min(sm_temp - Ea[t], 0)\n",
    "        # Adjust Ea by an amount equal to the possible negative sm amount or to\n",
    "        # the possible sm amount above Sm.\n",
    "\n",
    "    ###########################################################################\n",
    "    # Groundwater dynamics\n",
    "    ###########################################################################\n",
    "        # slow flow\n",
    "        QsL[t] = Rs * sL[t]\n",
    "        sL[t+1] = sL[t] + (1-alfa)*Pe[t] - QsL[t]\n",
    "        # fast flow\n",
    "        sF1[t+1] = sF1[t] +  alfa*Pe[t] - Rf*sF1[t]\n",
    "        sF2[t+1] = sF2[t] +  Rf*sF1[t] - Rf*sF2[t]\n",
    "        sF3[t+1] = sF3[t] +  Rf*sF2[t] - Rf*sF3[t]\n",
    "        QsF[t] = Rf * sF3[t]\n",
    "\n",
    "    Q_sim = QsL + QsF\n",
    "    STATES = np.column_stack((sm, sL, sF1, sF2, sF3))\n",
    "    FLUXES = np.column_stack((Pe, Ea, QsL, QsF))\n",
    "\n",
    "    return Q_sim, STATES, FLUXES\n",
    "\n",
    "\n",
    "def oat_function(Sm = 200, beta = 0.5, alpha = 0.7, Rs = 0.05, Rf = 0.6, rain_e = 1):\n",
    "    # Set a tentative parameterization:\n",
    "    param = np.array([Sm, beta, alpha, Rs, Rf, rain_e]) # Sm (mm), beta (-), alfa (-), Rs (-), Rf (-), rain_e (-)\n",
    "    # Run simulation:\n",
    "    flow_sim, _, _ = hymod_sim_mod(param, rain, evap)\n",
    "    # Plot results:\n",
    "    plt.figure(figsize=[15,3])\n",
    "    plt.plot(flow, color=[0.7, 0.7, 0.7]) # observed flow\n",
    "    plt.plot(flow_sim, 'k') # simulated flow\n",
    "    plt.ylabel('flow (mm/day)')\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.legend(['obs', 'sim'])\n",
    "    plt.show()\n",
    "    \n",
    "interact(oat_function, Sm = (0, 400, 1), beta = (0, 2, 0.1), alpha = (0,1,0.1), Rs = (0,0.1,0.01), Rf = (0.1,1,0.1), rain_e = (0.7, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad5b46",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "One-At-a-Time (OAT) effect: change one parameter (e.g. alfa) and repeat the previous steps.\n",
    "- What is the effect of varying this parameter (and the others)?\n",
    "- Which parameter controls which characteristic (timing, peak, recession phase, etc.) of the simulated flow time series?\n",
    "- Which parameters seem to mostly influence the output?\n",
    "- What are the pros and cons of OAT sensitivity analysis?\n",
    "\n",
    "## 2. Visual and qualitative Global Sensitivity Analysis\n",
    " In this section, we run Monte Carlo (MC) simulations of the model against a certain number of input (parameter) samples. Each model simulation provides a times series of runoff predictions. To measure the accuracy of each of these times series with respect to observations, we define two aggregate output metrics to be used for the subsequent steps:\n",
    "- the Root Mean Squared Error (RMSE) of the streamflow predictions\n",
    "- the volumetric Bias (BIAS) of the streamflow predictions\n",
    "\n",
    "Input (parameter) sampling (this involves a number of choices that will be  assessed and revised later on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab1d970",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define input variability space\n",
    "X_Labels = ['Sm', 'beta', 'alfa', 'Rs', 'Rf', 'rain_e'] # Name of parameters (used to customize plots)\n",
    "M = len(X_Labels) # Number of parameters\n",
    "distr_fun = st.uniform # Parameter distributions\n",
    "xmin = [0,   0, 0, 0.0, 0.1, 0.7] # Parameter ranges (lower bound)\n",
    "xmax = [400, 2, 1, 0.1, 1.0, 1.0] # Parameter ranges (upper bound)\n",
    "# The shape parameters of the uniform distribution are the lower limit and the\n",
    "# difference between lower and upper limits:\n",
    "distr_par = [np.nan] * M\n",
    "for i in range(M):\n",
    "    distr_par[i] = [xmin[i], xmax[i] - xmin[i]]\n",
    "\n",
    "# Choose sampling strategy and size:\n",
    "samp_strat = 'lhs' # sampling strategy\n",
    "# options:\n",
    "# 'lhs' = Latin Hypercube sampling\n",
    "# 'rsu' = Random uniform sampling\n",
    "N = 150 # Choose the number of samples\n",
    "\n",
    "# Perform sampling:\n",
    "X = AAT_sampling(samp_strat, M, distr_fun, distr_par, N)\n",
    "\n",
    "# If you want to see what the sample 'X' looks like:\n",
    "print(X[0:10, :]) # Print to screen the first 10 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a626d98",
   "metadata": {},
   "source": [
    "Execute the model against all the input samples in 'X':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c9a39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "QQ = model_execution(hymod_sim_mod, X, rain, evap)\n",
    "\n",
    "# Plot Monte Carlo (MC) simulations results and compare with data:\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.plot(flow, color=[0.7, 0.7, 0.7]) # plot for legend\n",
    "plt.plot(np.transpose(QQ), 'k', linewidth = 0.5)\n",
    "plt.plot(flow, color=[0.7, 0.7, 0.7])\n",
    "plt.ylabel('flow (mm/day)'); plt.xlabel('time (days)')\n",
    "plt.legend(['obs', 'sim'])\n",
    "plt.title(\"Model execution with N = %d\" % N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c81b6",
   "metadata": {},
   "source": [
    "### Let's do it more interactive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ec20d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sampling_function(samp_strat='lhs', N = 150):\n",
    "    \n",
    "    # Perform sampling:\n",
    "    sampling_function.X = AAT_sampling(samp_strat, M, distr_fun, distr_par, N)\n",
    "    \n",
    "    # Execute the model against all the input samples in 'X':\n",
    "    sampling_function.QQ = model_execution(hymod_sim_mod, sampling_function.X, rain, evap)\n",
    "\n",
    "    # Plot Monte Carlo (MC) simulations results and compare with data:\n",
    "    plt.figure(figsize=[15,5])\n",
    "    plt.plot(flow, color=[0.7, 0.7, 0.7]) # plot for legend\n",
    "    plt.plot(np.transpose(sampling_function.QQ), 'k',linewidth = 0.5);\n",
    "    plt.plot(flow, color=[0.7, 0.7, 0.7])\n",
    "    plt.ylabel('flow (mm/day)'); plt.xlabel('time (days)')\n",
    "    plt.legend(['obs', 'sim'])\n",
    "    plt.title(\"Model execution with N = %d\" % N)\n",
    "    plt.show()\n",
    "\n",
    "sampling_interact = interact(sampling_function,samp_strat=['lhs','rsu'], N = (10,300,10),continuous_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28672c3a",
   "metadata": {},
   "source": [
    "Here we retreive the values selected with the sliders in the interactive figure above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364c6d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samp_strat = sampling_interact.widget.kwargs[\"samp_strat\"]\n",
    "N          = sampling_interact.widget.kwargs[\"N\"]\n",
    "QQ = sampling_function.QQ\n",
    "X = sampling_function.X\n",
    "# print the selected sample size\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf08c1",
   "metadata": {},
   "source": [
    "Aggregate time series into various scalar output metric(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677adbaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "YY = np.nan * np.ones((N, 2))\n",
    "YY[:, 0] = RMSE(QQ[:, warmup:365], flow[warmup:365])\n",
    "YY[:, 1] = BIAS(QQ[:, warmup:365], flow[warmup:365])\n",
    "\n",
    "# If you want to see what the samples in 'YY' looks like:\n",
    "print(YY.shape) # Check the shape of 'YY'\n",
    "print(YY[0:10, :]) # Print to screen the first 10 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5434d",
   "metadata": {},
   "source": [
    "Let's plot the scatter plots of the input (parameter) samples against their corresponding RMSE or BIAS (you can choose one or the other interactively)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fdede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def output_metric_interact(metric):\n",
    "    if metric == 'RMSE': \n",
    "        i = 0\n",
    "    elif metric == 'BIAS': \n",
    "        i = 1\n",
    "    \n",
    "    Y = YY[:, i]; \n",
    "    Y_Label = metric\n",
    "\n",
    "    # Scatter plots of the output metric against input samples:\n",
    "    plt.figure(figsize=[15,2])\n",
    "    pf.scatter_plots(X, Y, Y_Label=Y_Label, X_Labels=X_Labels, n_col = 6)\n",
    "    plt.suptitle(\"Scatter plots with N = %d\" % N + ', ' + Y_Label, y = 0.95)\n",
    "    plt.show()\n",
    "  \n",
    "aggregate_interact = interact(output_metric_interact, metric = ['RMSE', 'BIAS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a83af0",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "- From these scatter plots, which parameter would you say is most influential? Why?\n",
    "- Are there parameters that are not influential at all?\n",
    "\n",
    "## 3. Regional Sensitivity Analysis\n",
    "In this section, we formally assess the sensitivity of the output metrics (RMSE and BIAS) to the model parameters through the Regional Sensitivity Analysis (RSA) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ccf8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RSA_function(metric = 'RMSE',threshold = 3.5):\n",
    "    \n",
    "    # Select the index of the output of interest:\n",
    "    if metric == 'RMSE': \n",
    "        i = 0\n",
    "    elif metric == 'BIAS': # for BIAS threshold higher than 2.5 you get an error\n",
    "        i = 1\n",
    "    \n",
    "    # Extract output of interest:\n",
    "    Y = YY[:, i]\n",
    "    \n",
    "    # Check that there are values below the threshold, otherwise plot a warning message\n",
    "    if np.all(np.logical_not(Y<threshold)):\n",
    "        print('Cannot find any output value below the threshold! Try increasing the threshold value')\n",
    "    \n",
    "    # Check that there are value above the threshold, otherwise plot a warning message\n",
    "    elif np.all(Y<threshold):\n",
    "        print('Cannot find any output value above the threshold! Try reducing the threshold value')\n",
    "    \n",
    "    # Perform RSA if there are values both below and above the threshold:\n",
    "    else:\n",
    "        Y_Label = metric\n",
    "\n",
    "        # Use the function RSA_indices_thres to split into behavioural (Y<threshold)\n",
    "        # and non-behavioural (Y>threshold) sample:\n",
    "        mvd, _, _, idxb = RSA_tr.RSA_indices_thres(X, Y, threshold)\n",
    "        # To learn what the function 'RSA_indices_thres' does, type:\n",
    "        # help(RSA_tr.RSA_indices_thres)\n",
    "        # idxb: indices of behavioural samples\n",
    "\n",
    "        # Plot behavioural MC simulations:\n",
    "        QQb = QQ[idxb, :]\n",
    "        plt.figure(figsize=[15,2])\n",
    "        plt.plot(flow, color=[0.7, 0.7, 0.7]) # plot for legend\n",
    "        plt.plot(np.transpose(QQb), 'r', linewidth = 0.5);\n",
    "        plt.plot(flow, color=[0.7, 0.7, 0.7])\n",
    "        plt.ylabel('flow (mm/day)'); plt.xlabel('time (days)')\n",
    "        plt.legend(['obs', 'sim'])\n",
    "        plt.title(\"Behavioural simulations with N = %d\" % N + ', threshold ' + Y_Label + ' = %2.2f' % threshold)\n",
    "        plt.show()\n",
    "\n",
    "        # Replot the results with the function `scatter_plots` highlighting the\n",
    "        # behavioural parameterizations:\n",
    "        plt.figure(figsize=[15,2])\n",
    "        pf.scatter_plots(X, Y, Y_Label=Y_Label, X_Labels=X_Labels, idx=idxb, n_col = 6)\n",
    "        plt.suptitle(\"Scatter plots with behavioural simulations with N = %d\" % N + ', ' + Y_Label  + \" = %2.2f\" % threshold)\n",
    "        plt.show()\n",
    "        # (red = behavioural, blue = non-behavioural)\n",
    "\n",
    "        # Plot CDFs of behavioural and non-behavioural input samples: (HOW CAN WE CHANGE THE SIZE OF THIS FIGURE?)\n",
    "        fig_cdfs = RSA_tr.RSA_plot_thres(X, idxb, X_Labels=X_Labels, n_col = 6)\n",
    "        plt.suptitle(\"CDFs with N = %d\" % N + ', ' + Y_Label + \" threshold = %2.2f\" % threshold)\n",
    "        hfig_cdfs = plt.gcf() # get figure handle\n",
    "        hfig_cdfs.set_size_inches(15, 2.5) # set width and height \n",
    "        plt.show()\n",
    "\n",
    "        # Check the value of KS statistic, i.e. the maximum vertical distance between the two\n",
    "        # CDFs of the inputs:\n",
    "        print('Value of the KS statistics between the two CDFs of the inputs: ' + str(mvd))\n",
    "\n",
    "        # Plot the KS statistic:\n",
    "        plt.figure(figsize=[5,2])\n",
    "        pf.boxplot1(mvd, X_Labels=X_Labels, Y_Label='KS statistic')\n",
    "        plt.title(\"KS with N = %d\" % N + ', ' + Y_Label + \" threshold = %2.2f\" % threshold)\n",
    "        hfig_box = plt.gcf() # get figure handle\n",
    "        hfig_box.set_size_inches(5, 3.5) # set width and height \n",
    "        plt.show()\n",
    "\n",
    "RSA_function(metric = 'RMSE', threshold = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b03bfa",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "- From the CDF plots, which parameter would you say are the most influential? Why?\n",
    "- Are these results consistent with the visual analysis of the scatter plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec51e8",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "- Are the KS values consistent with the visual inspection of the CDF plots?\n",
    "- Did you get the same KS values as the other participants? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29691e1",
   "metadata": {},
   "source": [
    "### 3.1 Assess the effect of the change in threshold\n",
    "\n",
    "**To do**: Run the cell below to plot an interactive figure and choose a different **threshold**\n",
    "- How have the results changed by changing the threshold of the output metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06abadb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the interactive figure\n",
    "threshold_interact = interact(RSA_function, metric = ['RMSE', 'BIAS'], threshold = (0.5,5,0.5),continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d8d5d",
   "metadata": {},
   "source": [
    "### 3.2 Assess the effect of the definition of output metric\n",
    "\n",
    "**To do**: Choose a different **output metric** (on the interactive figure above).\n",
    "- Does the answer change depending on the performance metric chosen? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be413fa9",
   "metadata": {},
   "source": [
    "### 3.3 Assess the robustness of the results (i.e. are the results sample independent?)\n",
    "To assess the robustness of the sensitivity indices, bootstrapping is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b45e6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y = YY[:, 0]; Y_Label = 'RMSE' # RMSE\n",
    "# Y = YY[:,1]; Y_Label = 'BIAS' # BIAS\n",
    "# Define the threshold:\n",
    "threshold = 3.5\n",
    "\n",
    "Nboot = 1000 # Number of resamples used for bootstrapping\n",
    "# Assess sensitivity indices with bootstrapping (WARNING: it may take some time\n",
    "# to run this line):\n",
    "mvd, _, _, idxb = RSA_tr.RSA_indices_thres(X, Y, threshold, Nboot=Nboot)\n",
    "# mvd has shape (Nboot, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf3f51",
   "metadata": {},
   "source": [
    "Compute mean and confidence intervals of the sensitivity indices (mvd, maximum vertical distance or KS statistics) across the bootstrap resamples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103c806",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alfa = 0.05 # Significance level for the confidence intervals estimated by\n",
    "# bootstrapping (default value is 0.05)\n",
    "mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd, alfa=alfa) # shape (M,)\n",
    "\n",
    "# The sensitivity indices with their 95% confidence intervals are plotted:\n",
    "plt.figure()\n",
    "pf.boxplot1(mvd_m, S_lb=mvd_lb, S_ub=mvd_ub, X_Labels=X_Labels, \\\n",
    "            Y_Label='KS statistic')\n",
    "plt.title(\"KS with 95%% CI, N = %d\" % N + \", \" + Y_Label + \" = %2.2f\" % threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25817bbc",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "- Are the sensitivity indices adequately estimated? \n",
    "- Is the sample size large enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd34e7c",
   "metadata": {},
   "source": [
    "Now choose the number of new samples to be added (N_new) and re-run the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a0da7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Choose the number of samples to be added:\n",
    "N_new = 2000 # size of new samples\n",
    "N2 = N_new + N # total sample size\n",
    "\n",
    "# Add new samples:\n",
    "X_N2 = AAT_sampling_extend(X, distr_fun, distr_par, N2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb21868",
   "metadata": {},
   "source": [
    "AAT_sampling_extend allows to extend an existing sample by choosing additional samples that maximise the spread in the input space X_N2 is the extended sample (it includes the already evaluated samples 'X' and the new ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa771bcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the shape is X_N2:\n",
    "print(X_N2.shape)\n",
    "\n",
    "# Extract new samples:\n",
    "X_new = X_N2[N:N2, :]\n",
    "# Check the shape of X_new:\n",
    "print(X_new.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae44ec",
   "metadata": {},
   "source": [
    "Compute the output metrics with new sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d910430",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Execute the model against the new inputs samples (WARNING: it may take\n",
    "# some time to run this line):\n",
    "QQ_new = model_execution(hymod_sim_mod, X_new, rain, evap)\n",
    "\n",
    "# Aggregate time series into various scalar output metric(s):\n",
    "YY_new = np.nan * np.ones((N_new, 2))\n",
    "YY_new[:, 0] = RMSE(QQ_new[:, warmup:365], flow[warmup:365])\n",
    "YY_new[:, 1] = BIAS(QQ_new[:, warmup:365], flow[warmup:365])\n",
    "\n",
    "# Combine old and new output samples:\n",
    "YY_N2 = np.concatenate((YY, YY_new))\n",
    "\n",
    "# Select the output metric to be analysed (uncomment option you want to view):\n",
    "Y_N2 = YY_N2[:, 0]; Y_Label = 'RMSE' # RMSE\n",
    "# Y_N2 = YY_N2[:, 1]; Y_Label = 'BIAS' # BIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf916c",
   "metadata": {},
   "source": [
    "Use the function RSA_indices_thres to split into behavioural (Y<threshold) and non-behavioural (Y>threshold) sample and calculate sensitivity indices with bootstrapping (WARNING: it may take some time to run this line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b9ec4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mvd_N2, _, _, idxb_N2 = RSA_tr.RSA_indices_thres(X_N2, Y_N2, threshold, Nboot=Nboot)\n",
    "# mvd_N2 has shape (Nboot, M)\n",
    "\n",
    "# Plot CDFs of behavioural and non-behavioural input samples:\n",
    "RSA_tr.RSA_plot_thres(X_N2, idxb_N2, X_Labels=X_Labels, n_col = 6)\n",
    "plt.suptitle(\"CDFs with N = %d\" % N2 + ', ' + Y_Label + \" = %2.2f\" % threshold)\n",
    "hfig_cdfs = plt.gcf() # get figure handle\n",
    "hfig_cdfs.set_size_inches(15, 2.5) # set width and height\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52e1ca",
   "metadata": {},
   "source": [
    "Compute mean and confidence intervals of the sensitivity indices (mvd, maximum vertical distance or KS statistics) across the bootstrap resamples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5305c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mvd_N2_m, mvd_N2_lb, mvd_N2_ub = aggregate_boot(mvd_N2, alfa=alfa) # shape (M,)\n",
    "\n",
    "# Check the bootstrap mean values of the KS statistic:\n",
    "print('Value of the bootstrap mean of the KS statistics between the two CDFs of the inputs: ' + str(mvd_N2_m))\n",
    "\n",
    "# Plot the sensitivity indices with their 95% confidence intervals:\n",
    "plt.figure()\n",
    "pf.boxplot1(mvd_N2_m, S_lb=mvd_N2_lb, S_ub=mvd_N2_ub, X_Labels=X_Labels, \\\n",
    "            Y_Label='KS statistic')\n",
    "plt.title(\"KS with 95%% CI, N = %d\" % N2 + ', ' + Y_Label + \" = %2.2f\" % threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05b6a8",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "- Has the ranking of the parameters changed?\n",
    "- Is the sample size large enough now?\n",
    "- How do the KS values you obtained compare to the results of the other participants?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5a271",
   "metadata": {},
   "source": [
    "Repeat computations using an increasing number of samples to assess convergence (WARNING: it may take some time to run this line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032968f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NN = np.array([150, 300, 500, 1000, 1500, 2150]) # increasing sample sizes\n",
    "Nboot = 100 # Number of resamples used for bootstrapping (suggested value \n",
    "# is 100 for the purpose of this exercise to  limit computational time, but \n",
    "# the recommended value for a rigorous analysis is 1000)\n",
    "mvd_cvg, _, _ = RSA_tr.RSA_convergence_thres(X_N2, Y_N2, NN, threshold, Nboot=Nboot)\n",
    "# mvd, spread and irr have shape (Nboot, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006231c9",
   "metadata": {},
   "source": [
    "Compute mean and confidence intervals of the sensitivity indices across the bootstrap resamples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ecbd3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mvd_cvg_m, mvd_cvg_lb, mvd_cvg_ub = aggregate_boot(mvd_cvg) # shape (R,M)\n",
    "# Plot the sensitivity measures as a function of the number of samples:\n",
    "plt.figure()\n",
    "pf.plot_convergence(mvd_cvg_m, NN, mvd_cvg_lb, mvd_cvg_ub, X_Label='no of samples',\n",
    "                    Y_Label='KS statistic', labelinput=X_Labels)\n",
    "hfig_cdfs = plt.gcf() # get figure handle\n",
    "hfig_cdfs.set_size_inches(10, 4) # set width and height \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe4e1c",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "- Has convergence been reached? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249afb8c",
   "metadata": {},
   "source": [
    "###  3.4 Assess the effect of the definition of the input factors' space of variability\n",
    "In this section we assess the effect of the input (parameter) ranges. This requires new model executions (WARNING: it may take some time to run this line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e472e2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Old input factors' ranges:\n",
    "#xmin = [0, 0, 0, 0, 0.1, 0.7] # Parameter ranges (lower bound)\n",
    "#xmax = [400, 2, 1, 0.1, 1, 1] # Parameter ranges (upper bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea6645",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Sm_widget    = IntRangeSlider(  min = 0,   max = 800)\n",
    "beta_widget  = FloatRangeSlider(min = 0,   max = 4)\n",
    "alpha_widget = FloatRangeSlider(min = 0,   max = 0.5)\n",
    "Rs_widget    = FloatRangeSlider(min = 0,   max = 0.4, value = (0,0.35))\n",
    "Rf_widget    = FloatRangeSlider(min = 0.4, max = 1  , value = (0.5,1))\n",
    "raine_widget = FloatRangeSlider(min = 0.5, max = 1)\n",
    "\n",
    "\n",
    "def input_range_function(Sm,beta,alpha,Rs, Rf,rain_e):\n",
    "    xmin2 = [Sm[0], beta[0], alpha[0], Rs[0], Rf[0], rain_e[0]] # Parameter ranges (lower bound)\n",
    "    xmax2 = [Sm[1], beta[1], alpha[1], Rs[1], Rf[1], rain_e[1]] # Parameter ranges (upper bound)\n",
    "    \n",
    "    # The shape parameters of the uniform distribution are the lower limit and the\n",
    "    # difference between lower and upper limits:\n",
    "    distr_par2 = [np.nan] * M\n",
    "    for i in range(M):\n",
    "        distr_par2[i] = [xmin2[i], xmax2[i] - xmin2[i]]\n",
    "\n",
    "    # Sample input factors' space using the larger sample size N2:\n",
    "    X_P2 = AAT_sampling(samp_strat, M, distr_fun, distr_par2, N2)\n",
    "\n",
    "    # Execute the model:\n",
    "    QQ_P2 = model_execution(hymod_sim_mod, X_P2, rain, evap)\n",
    "\n",
    "    # Aggregate time series into various scalar output metric(s):\n",
    "    YY_P2 = np.nan * np.ones((N2, 2))\n",
    "    YY_P2[:, 0] = RMSE(QQ_P2[:, warmup:365], flow[warmup:365])\n",
    "    YY_P2[:, 1] = BIAS(QQ_P2[:, warmup:365], flow[warmup:365])\n",
    "\n",
    "    # Select the output metric to be analysed (uncomment option you want to view):\n",
    "    Y_P2 = YY_P2[:, 0]; Y_Label = 'RMSE' # RMSE\n",
    "    # Y_P2 = YY_P2[:, 1]; Y_Label = 'BIAS' # BIAS\n",
    "    \n",
    "    # Define the threshold:\n",
    "    threshold = 3.5\n",
    "\n",
    "    # Use the function RSA_indices_thres to split into behavioural (Y<threshold)\n",
    "    # and non-behavioural (Y>threshold) sample and calculate sensitivity indices\n",
    "    # with bootstrapping (WARNING: it may take some time to run this line):\n",
    "    mvd_P2, _, _, idxb_P2 = RSA_tr.RSA_indices_thres(X_P2, Y_P2, threshold, Nboot=Nboot)\n",
    "    # mvd_N2 has shape (Nboot, M)\n",
    "\n",
    "    # Visualize the scatter plots:\n",
    "    # Old parameterisation:\n",
    "    plt.figure()\n",
    "    pf.scatter_plots(X_N2, Y_N2, Y_Label=Y_Label, X_Labels=X_Labels, idx=idxb_N2, n_col = 6)\n",
    "    plt.suptitle(\"Scatter plots with old parameterisation with N = %d\" % N2 + ', ' + Y_Label  + \" = %2.2f\" % threshold)\n",
    "    hfig_scat = plt.gcf() # get figure handle\n",
    "    hfig_scat.set_size_inches(15, 2.5) # set width and height\n",
    "    plt.show()\n",
    "    # New parameterisation   : \n",
    "    plt.figure()\n",
    "    pf.scatter_plots(X_P2, Y_P2, Y_Label=Y_Label, X_Labels=X_Labels, idx=idxb_P2, n_col = 6)\n",
    "    plt.suptitle(\"Scatter plots with new parameterisation with N = %d\" % N2 + ', ' + Y_Label  + \" = %2.2f\" % threshold)\n",
    "    hfig_scat = plt.gcf() # get figure handle\n",
    "    hfig_scat.set_size_inches(15, 2.5) # set width and height\n",
    "    plt.show()\n",
    "    # (red = behavioural, blue = non-behavioural)\n",
    "\n",
    "    # Plot CDFs of behavioural and non-behavioural input samples:\n",
    "    RSA_tr.RSA_plot_thres(X_P2, idxb_P2, X_Labels=X_Labels, n_col = 6)\n",
    "    plt.suptitle(\"CDFs with new parameterisation, N = %d\" % N2 + ', ' + Y_Label + \" = %2.2f\" % threshold)\n",
    "    hfig_cdfs = plt.gcf() # get figure handle\n",
    "    hfig_cdfs.set_size_inches(15, 2.5) # set width and height\n",
    "    plt.show()\n",
    "    # (red = behavioural, blue = non-behavioural)\n",
    "\n",
    "    # Compute mean and confidence intervals of the sensitivity indices (mvd,\n",
    "    # maximum vertical distance or KS statistics) across the bootstrap resamples:\n",
    "    mvd_P2_m, mvd_P2_lb, mvd_P2_ub = aggregate_boot(mvd_P2, alfa=alfa) # shape (M,)\n",
    "\n",
    "    # Plot the sensitivity indices with their 95% confidence intervals:\n",
    "    plt.figure()\n",
    "    pf.boxplot1(mvd_P2_m, S_lb=mvd_P2_lb, S_ub=mvd_P2_ub, X_Labels=X_Labels, \\\n",
    "                Y_Label='KS statistic')\n",
    "    plt.title(\"KS with 95%% CI, new par, N = %d\" % N2 + ', ' + Y_Label + \" = %2.2f\" % threshold)\n",
    "    plt.show()\n",
    "\n",
    "interact(input_range_function,Sm = Sm_widget, beta = beta_widget, alpha = alpha_widget, Rs = Rs_widget, Rf = Rf_widget, \\\n",
    "         rain_e = raine_widget, \\\n",
    "         continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136aa824",
   "metadata": {},
   "source": [
    "**To do**:\n",
    "- Is the sample size large enough?\n",
    "- How have the sensitivity indices changed by changing the range of variability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ad50e",
   "metadata": {},
   "source": [
    "## 4. Regional Sensitivity Analysis based on grouping\n",
    "In this section, we assess the sensitivity using the RSA method based on  grouping. This variant does not require the definition of a single threshold on the output value. It consists of splitting the input factor sample into a given number of groups (e.g. ten) according to the associated output value. \n",
    "\n",
    "In our application, we use ten intervals of increasing output value, designed so to have an equal number of data points in each group. The corresponding ten CDFs are then derived for each input factor.\n",
    "\n",
    "We can apply this method to the input-output sample that we have already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71beef33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select the output metric to be analysed (uncomment option you want to view):\n",
    "Y_N2 = YY_N2[:, 0]; Y_Label = 'RMSE' # RMSE\n",
    "# Y_N2 = YY_N2[:, 1]; Y_Label = 'BIAS' # BIAS\n",
    "\n",
    "# Set number of groups:\n",
    "ngroup = 10 \n",
    "# Perform RSA based on grouping:\n",
    "_, _, _, _, _, _, idx_gp, Yk = RSA_gp.RSA_indices_groups(X_N2, Y_N2, ngroup=ngroup)\n",
    "# idx_gp: indices of the ten groups\n",
    "# Yk: range of values of the output\n",
    "    \n",
    "# Look at the range of values of the output in the ten groups:\n",
    "print('Range of values of the output in the ten groups:\\n' + str(Yk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebaed57",
   "metadata": {},
   "source": [
    "Plot parameter CDFs corresponding to the ten groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d70606",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RSA_gp.RSA_plot_groups(X_N2, idx_gp, Yk, X_Labels=X_Labels, legend_title=Y_Label, n_col = 6)\n",
    "plt.suptitle(\"CDFs with N = %d\" % N2 + ', ' + Y_Label)\n",
    "hfig_cdfs = plt.gcf() # get figure handle\n",
    "hfig_cdfs.set_size_inches(15, 2.5) # set width and height\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872540c",
   "metadata": {},
   "source": [
    "**To do**: \n",
    "- From the CDF plots, which parameter would you say is most influential? Why?\n",
    "- Are the results of RSA based on grouping consistent with the results of RSA based on threshold?\n",
    "- Which additional information is provided by RSA based on grouping?\n",
    "\n",
    "Here we only performed a visual analysis of the ten CDFs, but sensitivity indices could also be computed based on the KS statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01703f",
   "metadata": {},
   "source": [
    "**References**:\n",
    "\n",
    "Boyle, D. (2001). Multicriteria calibration of hydrological models. PhD thesis. \n",
    "University of Arizona, Tucson.\n",
    "\n",
    "Noacco et al. (2019). Matlab/R workflows to assess critical choices in\n",
    "Global Sensitivity Analysis using the SAFE toolbox. MethodsX. 6. 2258-2280.\n",
    "\n",
    "Pianosi et al. (2015). A Matlab toolbox for Global Sensitivity Analysis.\n",
    "Environmental Modelling and Software. 70. 80-85.\n",
    "\n",
    "Pianosi et al. (2016). Sensitivity analysis of environmental models:\n",
    "A systematic review with practical workflow. Environmental Modelling and\n",
    "Software. 79. 214-232.\n",
    "\n",
    "Saltelli et al. (2008). Global Sensitivity Analysis, The Primer, John Wiley\n",
    "Sons. Ltd. Chichester, UK.\n",
    "\n",
    "Sarrazin et al. (2016). Global Sensitivity Analysis of environmental models:\n",
    "Convergence and validation. Environmental Modelling and Software. 79.\n",
    "135-162.\n",
    "\n",
    "Sorooshian at al. (1983). Evaluation of maximum likelihood parameter\n",
    "estimation techniques for conceptual rainfall-runoff models: Influence of\n",
    "calibration data variability and length on model credibility. Water Resour.\n",
    "Res. 19. 251-259.\n",
    "\n",
    "Spear and Hornberger (1980). Eutrophication in peel inlet e II.\n",
    "Identification of critical uncertainties via generalized sensitivity analysis.\n",
    "Water Research. 14(1). 43-49.\n",
    "\n",
    "Wagener et al. (2001). A framework for development and application of\n",
    "hydrological models. Hydrol. Earth Syst. Sci.. 5. 13-26.\n",
    "\n",
    "Wagener and Pianosi (2019). What has Global Sensitivity Analysis ever done for \n",
    "us? A systematic review to support scientific advancement and to inform policy-\n",
    "making in earth system modelling. Earth-Science Reviews. 194. 1-18.\n",
    "\n",
    "Young et al. (1978). Modelling badly defined systems: some further thoughts.\n",
    "In: Proceedings SIMSIG Conference. Canberra. 24-32."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
